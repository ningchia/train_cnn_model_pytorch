import torch
import torch.nn as nn
from torchvision import transforms
import cv2
import numpy as np
import os
import sys
import time
from PIL import Image, ImageGrab 
from typing import List, Optional, Any, Tuple, Literal

# --- å°å…¥æ¨¡å‹çµæ§‹ (å‡è¨­ MobileNetTransfer å·²åœ¨ model_defs ä¸­) ---
# ç¢ºä¿ model_defs æª”æ¡ˆåŒ…å« MobileNetTransfer é¡åˆ¥
try:
    from model_defs import MobileNetTransfer 
except ImportError:
    print("éŒ¯èª¤: æ‰¾ä¸åˆ° model_defs æ¨¡çµ„æˆ– MobileNetTransfer é¡åˆ¥ã€‚è«‹æª¢æŸ¥æª”æ¡ˆã€‚")
    sys.exit(1)

# --- å°å…¥ torchao çš„é‡åŒ– API ---
try:
    from torchao.quantization import quantize_ 
    from torchao.quantization import Int8DynamicActivationInt8WeightConfig 
except ImportError:
    quantize_ = None
    Int8DynamicActivationInt8WeightConfig = None
    
# --- 1. é…ç½®èˆ‡åƒæ•¸è¨­å®š ---
MODEL_SAVE_PATH = "trained_model"
INT8_MODEL_FILE = "quantized_mobilenet_cifar10_int8.pth"
INT8_MODEL_PATH = os.path.join(MODEL_SAVE_PATH, INT8_MODEL_FILE)

NUM_CLASSES = 10 
CLASS_NAMES = [
    "plane", "car", "bird", "cat", "deer", 
    "dog", "frog", "horse", "ship", "truck"
]

# ğŸŒŸ è¨­ç½®é» 1: é¸æ“‡æ¨è«–è£ç½® (å¯é¸ 'cpu' æˆ– 'cuda') ğŸŒŸ
# æ³¨æ„ï¼šè‹¥é¸æ“‡ 'cuda' ä¸”å®‰è£äº† PyTorch 2.x+ï¼Œæ¨¡å‹æœƒé€é torch.compile é€²è¡Œå„ªåŒ–ã€‚
# å¦å‰‡ï¼ŒINT8 æ¨è«–åœ¨ CUDA ä¸Šå¯èƒ½æœƒå¤±æ•—æˆ–æ•ˆç‡æ¥µä½ã€‚
INFERENCE_DEVICE: Literal['cpu', 'cuda'] = 'cpu' 
DEVICE = torch.device(INFERENCE_DEVICE)

# --- è¼”åŠ©å‡½å¼ï¼šç”Ÿæˆæç¤ºç•«é¢ (èˆ‡åŸè…³æœ¬ç›¸åŒ) ---
def create_info_image(text: str, size: tuple = (400, 600)) -> np.ndarray:
    """ å‰µå»ºä¸€å€‹é»‘è‰²èƒŒæ™¯ï¼Œå¸¶æœ‰æŒ‡å®šæ–‡å­—çš„ OpenCV åœ–åƒã€‚ """
    height, width = size
    img = np.zeros((height, width, 3), dtype=np.uint8)
    # ... (å…¶é¤˜æ–‡å­—ç¹ªè£½é‚è¼¯ç•¥) ...
    cv2.putText(img, text, (10, 50), 
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2, cv2.LINE_AA)
    return img

# --- è¼”åŠ©å‡½å¼ï¼šPIL è½‰ OpenCV (èˆ‡åŸè…³æœ¬ç›¸åŒ) ---
def pil_to_cv2_with_text(pil_image: Image.Image, text: str) -> np.ndarray:
    # ... (ç¨‹å¼ç¢¼ç•¥) ...
    cv_image = np.array(pil_image)
    cv_image = cv2.cvtColor(cv_image, cv2.COLOR_RGB2BGR)
    cv2.putText(cv_image, text, (10, 30), 
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2, cv2.LINE_AA)
    return cv_image

# --- è¼”åŠ©å‡½å¼ï¼šæ•¸æ“šè½‰æ› (èˆ‡åŸè…³æœ¬ç›¸åŒ) ---
def create_data_transform() -> transforms.Compose:
    IMAGENET_MEAN = [0.485, 0.456, 0.406]
    IMAGENET_STD = [0.229, 0.224, 0.225]
    
    return transforms.Compose([
        transforms.Resize((224, 224)), 
        transforms.ToTensor(), 
        transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD) 
    ])

# --- 2. æ ¸å¿ƒï¼šè¼‰å…¥ INT8 æ¨¡å‹å‡½å¼ (æ”¯æ´ CPU/GPU æ¨è«–) ---
def load_int8_model(num_classes: int) -> nn.Module:
    """è¼‰å…¥ INT8 æ¨¡å‹ä¸¦å°‡å…¶ç§»å‹•åˆ°æŒ‡å®šçš„ DEVICEã€‚"""
        
    if quantize_ is None:
         raise ImportError("éŒ¯èª¤: æœªæ‰¾åˆ° torchao å‡½å¼åº«ã€‚è«‹é‹è¡Œ pip install torchaoã€‚")
    
    if not os.path.exists(INT8_MODEL_PATH):
        raise FileNotFoundError(f"éŒ¯èª¤: æ‰¾ä¸åˆ° INT8 æ¨¡å‹æª”æ¡ˆ {INT8_MODEL_PATH}ã€‚è«‹å…ˆé€²è¡Œé‡åŒ–ã€‚")

    # æ­¥é©Ÿ 1: åˆå§‹åŒ– FP32 æ¨¡å‹çµæ§‹ (ä½œç‚ºé‡åŒ–çš„èµ·é»)
    model = MobileNetTransfer(num_classes=num_classes, use_pretrained=False).to(torch.device('cpu')) 
    
    # æ­¥é©Ÿ 2: è½‰æ›ç‚º INT8 é‡åŒ–çµæ§‹
    quant_config = Int8DynamicActivationInt8WeightConfig()
    quantize_(model, quant_config) # In-place è½‰æ›
    
    # æ­¥é©Ÿ 3: è¼‰å…¥ INT8 æ¬Šé‡
    int8_state_dict = torch.load(INT8_MODEL_PATH, map_location=torch.device('cpu'))
    
    try:
        model.load_state_dict(int8_state_dict) 
    except Exception as e:
        raise ValueError(f"éŒ¯èª¤: è¼‰å…¥ INT8 æ¬Šé‡å¤±æ•—ã€‚çµæ§‹å¯èƒ½ä¸åŒ¹é…ã€‚\nè¨Šæ¯: {e}")

    # æ­¥é©Ÿ 4: ç§»å‹•æ¨¡å‹åˆ°æ¨è«–è£ç½®ä¸¦æ‡‰ç”¨å„ªåŒ–
    if INFERENCE_DEVICE == 'cuda':
        if not torch.cuda.is_available():
            raise RuntimeError("éŒ¯èª¤: å·²é¸æ“‡ 'cuda' æ¨è«–ï¼Œä½†æœªåµæ¸¬åˆ° CUDA è£ç½®ã€‚")
            
        # âš ï¸ å¿…é ˆå…ˆå°‡æ¨¡å‹ç§»å‹•åˆ° CUDA è£ç½®
        model.to(DEVICE)
        
        # âš ï¸ ä½¿ç”¨ torch.compile é€²è¡Œ GPU é‡åŒ–æ¨è«–å„ªåŒ– (ç¹é nn.quantized æ¨¡çµ„é™åˆ¶)
        if torch.__version__ >= '2.0':
            print("â³ æ­£åœ¨å° INT8 æ¨¡å‹åŸ·è¡Œ torch.compile å„ªåŒ– (åˆæ¬¡é‹è¡Œè¼ƒæ…¢)...")
            model = torch.compile(model)
        else:
            print("è­¦å‘Š: PyTorch ç‰ˆæœ¬ä½æ–¼ 2.0ï¼Œç„¡æ³•ä½¿ç”¨ torch.compile é€²è¡Œ GPU INT8 å„ªåŒ–ã€‚æ¨è«–å¯èƒ½æ•ˆç‡ä½ä¸‹ã€‚")

    elif INFERENCE_DEVICE == 'cpu':
        # ç¢ºä¿æ¨¡å‹åœ¨ CPU ä¸Š (å®ƒå·²ç¶“åœ¨ CPU ä¸Šäº†)
        pass 

    model.eval() # è¨­å®šç‚ºè©•ä¼°æ¨¡å¼
    print(f"âœ… INT8 æ¨¡å‹å·²è¼‰å…¥ä¸¦éƒ¨ç½²æ–¼ {DEVICE}ã€‚")
    return model

# --- 3. æ¨è«–æ ¸å¿ƒ ---
def inference_on_image(model: nn.Module, pil_image: Image.Image, data_transform: transforms.Compose, class_names: List[str], device: torch.device) -> Tuple[np.ndarray, str, float, float]:
    """ åŸ·è¡Œæ¨è«–ï¼Œä¸¦è¿”å›çµæœã€é æ¸¬é¡åˆ¥ã€ç½®ä¿¡åº¦å’Œæ¨è«–æ™‚é–“ã€‚ """
    
    # 1. åŸ·è¡Œè½‰æ›
    input_tensor = data_transform(pil_image)
    # 2. å¢åŠ  Batch ç¶­åº¦ (C, H, W) -> (1, C, H, W)ï¼Œä¸¦ç§»å‹•åˆ°è£ç½®
    input_batch = input_tensor.unsqueeze(0).to(device) 

    # --- æ¨è«– ---
    with torch.no_grad():
        start_time = time.time()
        output = model(input_batch)
        end_time = time.time()
    
    inference_time = (end_time - start_time) * 1000 # è½‰ç‚ºæ¯«ç§’
    
    # --- çµæœè§£ç¢¼ ---
    probabilities = torch.nn.functional.softmax(output[0], dim=0)
    confidence, predicted_index = torch.max(probabilities, 0)
    
    predicted_class = class_names[predicted_index.item()]
    confidence_percent = confidence.item() * 100

    # æ ¼å¼åŒ–è¼¸å‡ºå­—ä¸²
    text = f"Class: {predicted_class} | Conf: {confidence_percent:.2f}% | Time: {inference_time:.2f}ms"
    
    # å°‡çµæœç¹ªè£½åˆ°åŸå§‹ç•«é¢ (BGR æ ¼å¼)
    result_cv_image = pil_to_cv2_with_text(pil_image, text)
    
    return result_cv_image, predicted_class, confidence_percent, inference_time


# --- 4. ä¸»åŸ·è¡Œæµç¨‹ ---
def main():
    print(f"--- å•Ÿå‹• INT8 æ¨¡å‹å¯¦æ™‚æ¨è«– (è£ç½®: {INFERENCE_DEVICE}) ---")
    
    try:
        # è¼‰å…¥ INT8 æ¨¡å‹
        model = load_int8_model(NUM_CLASSES)
        data_transform = create_data_transform()

        # è®Šæ•¸ç”¨æ–¼è¿½è¹¤å‰ªè²¼ç°¿ç‹€æ…‹
        last_image_hash: Optional[int] = None
        display_text = f"Ready: INT8 on {INFERENCE_DEVICE}. Paste image to infer."
        display_image: np.ndarray = create_info_image(display_text)
        
        while True:
            should_infer = False
            pil_image: Optional[Image.Image] = None
            
            # A. å˜—è©¦å¾å‰ªè²¼ç°¿è®€å–åœ–åƒ
            try:
                current_pil_image = ImageGrab.grabclipboard()
                
                if current_pil_image is not None and isinstance(current_pil_image, Image.Image):
                    # æª¢æŸ¥åœ–åƒæ˜¯å¦æ”¹è®Š
                    current_image_hash = hash(current_pil_image.tobytes())
                    
                    if current_image_hash != last_image_hash:
                        pil_image = current_pil_image
                        last_image_hash = current_image_hash
                        should_infer = True
                        # print("\nâœ¨ åµæ¸¬åˆ°å‰ªè²¼ç°¿åœ–åƒæ›´æ–°ï¼Œæ­£åœ¨æ¨è«–...") # é¿å…é »ç¹è¼¸å‡º
                
            except Exception as e:
                # è™•ç†å‰ªè²¼ç°¿è®€å–éŒ¯èª¤
                display_image = create_info_image("ERROR: Cannot read clipboard.")
                # print(f"ğŸ”¥ å‰ªè²¼ç°¿è®€å–éŒ¯èª¤: {e.__class__.__name__}   ", end='\r')
            
            # B. å¦‚æœéœ€è¦æ¨è«–
            if should_infer and pil_image is not None:
                try:
                    result_cv_image, predicted_class, confidence_percent, time_ms = inference_on_image(
                        model, pil_image, data_transform, CLASS_NAMES, DEVICE
                    )
                    
                    # æ›´æ–°é¡¯ç¤ºåœ–ç‰‡
                    display_image = result_cv_image
                    
                    # åœ¨å‘½ä»¤åˆ—è¼¸å‡ºçµæœ
                    print(f"ğŸ‘ï¸ é æ¸¬: {predicted_class} | ç½®ä¿¡åº¦: {confidence_percent:.2f}% | è€—æ™‚: {time_ms:.2f}ms   ", end='\r')
                
                except Exception as e:
                    # æ¨è«–éç¨‹ä¸­çš„éŒ¯èª¤
                    display_image = create_info_image(f"Inference Error: {e.__class__.__name__}")
                    print(f"ğŸ”¥ æ¨è«–éŒ¯èª¤: {e.__class__.__name__}   ", end='\r')

            # C. é¡¯ç¤ºçµæœ
            cv2.imshow(f'INT8 Inference ({INFERENCE_DEVICE.upper()} Mode - Press "q" to quit)', display_image)
            
            # D. æª¢æŸ¥æŒ‰éµ
            key = cv2.waitKey(10) & 0xFF
            if key == ord('q'):
                break
        
    except (FileNotFoundError, ValueError, ImportError, RuntimeError) as e:
        print(f"\n\n[è‡´å‘½éŒ¯èª¤] {e}")
        cv2.destroyAllWindows()
        sys.exit(1)
    except Exception as e:
        import traceback
        traceback.print_exc()
        print(f"\n\n[ä¸€èˆ¬éŒ¯èª¤] ç™¼ç”ŸéŒ¯èª¤: {e.__class__.__name__}")
        cv2.destroyAllWindows()
        sys.exit(1)
        
    finally:
        cv2.destroyAllWindows()
        print("\n\nğŸ‘‹ ç¨‹å¼çµæŸã€‚")

if __name__ == '__main__':
    main()